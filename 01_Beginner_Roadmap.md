# üìò AI Engineer Learning Roadmap ‚Äî Beginner Level

> **Foundation Phase:** Python, Mathematics, Data Science Fundamentals
>
> *Based on [Krish Naik's Perfect Roadmap](https://github.com/krishnaik06/Perfect-Roadmap-To-Learn-Data-Science-In-2025), university curricula, and industry standards.*

[![Level](https://img.shields.io/badge/Level-Beginner-brightgreen?style=flat-square)]()
[![Duration](https://img.shields.io/badge/Duration-2--3%20Months-blue?style=flat-square)]()
[![XP](https://img.shields.io/badge/Total%20XP-10%2C000-yellow?style=flat-square)]()
[![Hours](https://img.shields.io/badge/Hours-160--200-orange?style=flat-square)]()

```
‚ö° Progress: [‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 0% ‚Äî Let's begin!
```

---

## üìë Table of Contents
- [Prerequisites](#prerequisites)
- [üéØ Learning Objectives](#-learning-objectives)
- [Module 1: Python Programming Foundations](#module-1-python-programming-foundations)
- [Module 2: Mathematics for AI](#module-2-mathematics-for-ai)
- [Module 3: Data Manipulation & Analysis](#module-3-data-manipulation--analysis)
- [Module 4: Data Visualization & Exploratory Data Analysis](#module-4-data-visualization--exploratory-data-analysis)
- [Module 5: Version Control & Development Tools](#module-5-version-control--development-tools)
- [üèÜ Capstone Project](#-capstone-project)
- [‚úÖ Assessment Checklist](#-assessment-checklist)
- [Next Steps](#next-steps)

---

## Prerequisites

### Required Before Starting:
- [ ] Computer with 8GB+ RAM (16GB recommended)
- [ ] Stable internet connection
- [ ] 20-25 hours/week available for focused study
- [ ] Growth mindset and commitment to consistent practice

### Helpful But Not Required:
- Basic understanding of high school algebra
- Any programming experience (even if not Python)
- Familiarity with command line/terminal

### Zero Programming Experience?
**Start here first (2-3 weeks):**
- [Python for Everybody Specialization (Coursera)](https://www.coursera.org/specializations/python) - FREE audit option
- [CS50's Introduction to Programming with Python (Harvard)](https://cs50.harvard.edu/python/2022/) - FREE

---

## üéØ Learning Objectives

By the end of this Beginner Roadmap, you will be able to:

1. Write clean, efficient Python code using OOP principles
2. Understand and apply mathematical concepts essential for AI/ML
3. Manipulate and analyze data using NumPy and Pandas
4. Create meaningful visualizations to communicate insights
5. Perform comprehensive exploratory data analysis (EDA)
6. Use Git/GitHub for version control and portfolio building
7. Set up and manage Python development environments
8. Complete 8-10 hands-on portfolio projects

---

## Module 1: Python Programming Foundations

**Duration:** 4-5 weeks | **‚ö° XP Reward:** 2,000 XP

### Week 1-2: Python Basics

#### üéØ Topics to Master:
- [ ] Python installation and setup (Anaconda, Jupyter, VS Code)
- [ ] Variables, data types, operators
- [ ] Strings, string methods, f-strings
- [ ] Lists, tuples, dictionaries, sets
- [ ] Control flow (if/elif/else)
- [ ] Loops (for, while), list comprehensions
- [ ] Functions, lambda functions
- [ ] Error handling (try/except)

#### üìö Resources:

<details>
<summary><strong>Primary Course (Choose ONE)</strong></summary>

- **[Krish Naik Complete Python Playlist](https://www.youtube.com/playlist?list=PLZoTAELRMXVNUL99R4bDlVYsncUNvwUBB)** - **HIGHLY RECOMMENDED**
  - Comprehensive Python tutorial from basics to advanced
  - Clear explanations with practical examples
  - Perfect for data science preparation
  - Time: ~15-20 hours

- **[Your Udemy: Complete Python Bootcamp](https://www.udemy.com/course/complete-python-bootcamp/)** - Sections 1-11
  - Time: ~20 hours
  - Focus: Interactive exercises and projects
  - RECOMMENDED START: Begin here if you own this course

</details>

<details>
<summary><strong>Free Alternatives</strong></summary>

- [Python Tutorial for Beginners (Programming with Mosh)](https://www.youtube.com/watch?v=_uQrJ0TkZlc) - 6 hours
- [Python for Beginners (Microsoft)](https://www.youtube.com/playlist?list=PLlrxD0HtieHhS8VzuMCfQD4uJ9yne1mE6) - FREE
- [Google's Python Class](https://developers.google.com/edu/python) - FREE with exercises

</details>

<details>
<summary><strong>Interactive Practice</strong></summary>

- [Python Track on Kaggle Learn](https://www.kaggle.com/learn/python) - 5 hours, FREE
- [Exercism Python Track](https://exercism.org/tracks/python) - FREE mentored exercises
- [HackerRank Python](https://www.hackerrank.com/domains/python) - FREE coding challenges

</details>

**Reference Documentation:**
- [Official Python Tutorial](https://docs.python.org/3/tutorial/)
- [Real Python Tutorials](https://realpython.com/) - Excellent written tutorials

#### üìã Step-by-Step Learning Path:

**Step 1: Environment Setup** (Day 1)
1. Download and install [Anaconda](https://www.anaconda.com/download)
   - This includes Python, Jupyter Notebook, and essential libraries
   - Verify installation by opening Anaconda Navigator
2. Install [VS Code](https://code.visualstudio.com/)
   - Add Python extension from VS Code marketplace
   - Configure Python interpreter (select Anaconda's Python)
3. Create your first Jupyter notebook
   - Open Jupyter Notebook from Anaconda Navigator
   - Create a new notebook and run `print("Hello, AI World!")`
   - Save it in a folder: `~/AI_Learning/Module1_Python/`

**Step 2: Watch & Code Along** (Days 2-7)
4. Start [Krish Naik Complete Python Playlist](https://www.youtube.com/playlist?list=PLZoTAELRMXVNUL99R4bDlVYsncUNvwUBB)
   - Watch videos 1-15 covering Python basics
   - Topics: Variables, data types, operators, strings, lists
   - Code along in Jupyter Notebook for EVERY example
   - Don't just watch - type every line of code yourself
   - Save notebooks in `01_python_basics/` folder
5. Alternative: If using Udemy Python Bootcamp
   - Complete Sections 1-6 (Introduction through Functions)
   - Do every coding exercise in the course
   - Take notes on concepts that are new to you

**Step 3: Structured Course** (Days 8-10)
6. Complete [Kaggle Python Course](https://www.kaggle.com/learn/python)
   - All 7 lessons (5 hours total)
   - Complete every exercise at the end of each lesson
   - Earn the Kaggle Python certificate
   - Topics covered: Syntax, functions, booleans, lists, loops, strings

**Step 4: Practice & Reinforce** (Days 11-12)
7. Solve problems on [HackerRank Python](https://www.hackerrank.com/domains/python)
   - Start with "Easy" difficulty
   - Complete at least 20 problems
   - Focus on: Introduction, Strings, Lists, Loops sections
   - Don't look at solutions immediately - struggle for 15 minutes first

**Step 5: Build Projects** (Days 13-14)
8. Build Project 1: Number Guessing Game
   - Requirements: Random number, user input, attempt counter
   - Don't look at solutions - try on your own first
   - If stuck for 30+ minutes, search for hints (not full code)
   - Push to GitHub when done
9. Build Project 2: To-Do List App
   - Requirements: Add task, view tasks, mark complete, delete
   - Start from scratch - no copy-paste
   - Test all functionality before considering it done
10. Build Project 3: Text Analysis Tool
    - Requirements: Read file, count words, find frequency, longest word
    - Implement error handling for file not found
    - Display results in a formatted way

**Daily Schedule Recommendation:**
- Days 1-7: 2 hours video + 1 hour coding practice
- Days 8-10: 2 hours structured course + 1 hour exercises
- Days 11-12: 3 hours problem-solving practice
- Days 13-14: 4 hours project building each day

#### üõ†Ô∏è Hands-On Projects:
1. **Number Guessing Game** (50 XP)
   - User vs Computer guessing game with attempts tracking
   - Skills: Variables, loops, conditionals, functions

2. **To-Do List Application** (100 XP)
   - CLI-based task manager with add/remove/view/complete features
   - Skills: Lists, dictionaries, file I/O, functions

3. **Text Analysis Tool** (150 XP)
   - Analyze text files: word count, frequency, longest word
   - Skills: String methods, dictionaries, file handling

**Achievement Unlocked:** üèÜ Python Initiate - Complete all Week 1-2 exercises

**Progress:** `[‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 20%`

[‚Üë Back to Top](#-table-of-contents)

---

### Week 3-4: Object-Oriented Programming & Advanced Python

#### üéØ Topics to Master:
- [ ] Object-Oriented Programming (OOP) concepts
- [ ] Classes and objects
- [ ] Inheritance, polymorphism, encapsulation
- [ ] Magic/dunder methods
- [ ] Modules and packages
- [ ] Virtual environments (venv, conda)
- [ ] Reading/writing files (CSV, JSON, text)
- [ ] Working with dates and times
- [ ] Regular expressions basics

#### üìö Resources:

<details>
<summary><strong>Primary Course</strong></summary>

- **[Krish Naik Complete Python Playlist](https://www.youtube.com/playlist?list=PLZoTAELRMXVNUL99R4bDlVYsncUNvwUBB)** - OOP sections
  - Excellent coverage of OOP concepts
  - Real-world examples

- **[Your Udemy: Complete Python Bootcamp](https://www.udemy.com/course/complete-python-bootcamp/)** - Sections 12-18
  - Focus on OOP sections intensively

</details>

<details>
<summary><strong>Free Video Resources</strong></summary>

- [Object Oriented Programming (OOP) in Python (Corey Schafer)](https://www.youtube.com/playlist?list=PL-osiE80TeTsqhIuOqKhwlXsIBIdSeYtc) - Excellent OOP series
- [Python OOP Tutorial (Tech With Tim)](https://www.youtube.com/watch?v=JeznW_7DlB0) - 45 minutes

</details>

**Interactive Practice:**
- [Object Oriented Programming in Python (Real Python)](https://realpython.com/python3-object-oriented-programming/)
- Practice OOP problems on [CodeWars](https://www.codewars.com/) (Python track)

#### üìã Step-by-Step Learning Path:

**Step 1: Watch OOP Fundamentals** (Days 1-4)
1. Watch [Krish Naik Python Playlist OOP section](https://www.youtube.com/playlist?list=PLZoTAELRMXVNUL99R4bDlVYsncUNvwUBB)
   - Focus on videos covering classes, objects, methods
   - Watch 2-3 videos per day (approximately videos 16-30)
   - Create a separate notebook for each OOP concept
   - Code every example shown in the videos
2. Alternative: [Corey Schafer OOP Series](https://www.youtube.com/playlist?list=PL-osiE80TeTsqhIuOqKhwlXsIBIdSeYtc)
   - Watch all 6 videos in the series (2 hours total)
   - Take notes on: classes, instance variables, class variables
   - Understand: inheritance, special methods, property decorators

**Step 2: Structured Course Deep Dive** (Days 5-7)
3. Complete Udemy Python Bootcamp Sections 12-18 (if you have access)
   - Section 12: OOP introduction and basics
   - Section 13: OOP challenge exercises
   - Section 14: Advanced OOP concepts
   - Complete ALL coding exercises
   - Do the OOP homework assignments
4. Read [Real Python OOP Tutorial](https://realpython.com/python3-object-oriented-programming/)
   - Take notes on key concepts
   - Type out all code examples yourself

**Step 3: Advanced Concepts** (Days 8-10)
5. Learn about modules and packages
   - Watch tutorials on creating your own modules
   - Understand `__init__.py` files
   - Learn about `if __name__ == "__main__":`
6. File handling practice
   - Work with CSV files using built-in csv module
   - Practice JSON reading/writing with json module
   - Learn different file modes (r, w, a, r+, etc.)
7. Virtual environments setup
   - Create a virtual environment using conda: `conda create -n myenv python=3.10`
   - Learn to activate/deactivate environments
   - Practice installing packages with pip

**Step 4: Practice OOP Problems** (Days 11-12)
8. Solve OOP challenges on [CodeWars](https://www.codewars.com/)
   - Filter for Python and OOP-related katas
   - Start with 7 kyu difficulty
   - Complete at least 10 OOP-focused problems
9. Create mini practice projects
   - Simple Calculator class with methods
   - Student/Course management system
   - Inventory tracker for items

**Step 5: Build Major Projects** (Days 13-14)
10. Build Project 4: Bank Account System
    - Create base Account class first
    - Add Savings and Checking child classes
    - Implement all required methods one at a time
    - Test each method before moving to next
    - Add transaction history using lists/files
11. Build Project 5: Library Management System
    - Plan your classes on paper first: Book, Member, Library
    - Create Book class with attributes and methods
    - Create Member class with borrowing limits
    - Create Library class to manage everything
    - Use JSON to save/load library state
    - Test with multiple books and members

**Daily Schedule Recommendation:**
- Days 1-7: 2 hours video learning + 1.5 hours coding along
- Days 8-10: 3 hours hands-on practice with concepts
- Days 11-12: 3 hours problem-solving on CodeWars
- Days 13-14: 5 hours project building each day

#### üõ†Ô∏è Hands-On Projects:
4. **Bank Account System** (200 XP)
   - Create Account class with deposit/withdraw/transfer methods
   - Multiple account types (Savings, Checking) using inheritance
   - Transaction history tracking
   - Skills: OOP, classes, inheritance, file I/O

5. **Library Management System** (250 XP)
   - Book, Member, and Library classes
   - Borrow/return functionality with due dates
   - Search and filter capabilities
   - Skills: OOP, multiple classes, datetime, JSON storage

**Achievement Unlocked:** üèÜ OOP Master - Build complex multi-class systems

**Progress:** `[‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 40%`

[‚Üë Back to Top](#-table-of-contents)

---

### Week 5: Python for Data Science Setup & Best Practices

#### üéØ Topics to Master:
- [ ] Jupyter Notebooks mastery
- [ ] Google Colab setup and usage
- [ ] NumPy basics (arrays, operations)
- [ ] Python debugging techniques
- [ ] Code style and PEP 8
- [ ] Writing documentation
- [ ] Testing basics (unittest)

#### üìö Resources:

**Jupyter & Colab:**
- [Jupyter Notebook Tutorial (Corey Schafer)](https://www.youtube.com/watch?v=HW29067qVWk) - 30 minutes
- [Google Colab Tutorial](https://www.youtube.com/watch?v=inN8seMm7UI) - 15 minutes

**NumPy Introduction:**
- [NumPy Tutorial for Beginners (freeCodeCamp)](https://www.youtube.com/watch?v=QUT1VHiLmmI) - 1 hour
- [NumPy Quickstart Tutorial](https://numpy.org/doc/stable/user/quickstart.html) - Official docs

**Code Quality:**
- [Writing Clean Python Code (Real Python)](https://realpython.com/python-pep8/)

#### üìã Step-by-Step Learning Path:

**Step 1: Master Jupyter & Colab** (Days 1-2)
1. Watch [Jupyter Notebook Tutorial (Corey Schafer)](https://www.youtube.com/watch?v=HW29067qVWk)
   - Learn keyboard shortcuts (Ctrl+Enter, Shift+Enter, etc.)
   - Practice creating markdown cells with headers, lists, code blocks
   - Create a sample notebook with mixed code and markdown
2. Set up [Google Colab](https://colab.research.google.com/)
   - Watch [Google Colab Tutorial](https://www.youtube.com/watch?v=inN8seMm7UI)
   - Learn how to mount Google Drive
   - Practice uploading files and installing packages
   - Create a "Colab Cheat Sheet" notebook for future reference
3. Jupyter best practices
   - Learn to restart kernel and clear outputs
   - Understand when to split cells
   - Practice naming notebooks descriptively

**Step 2: NumPy Fundamentals** (Days 3-5)
4. Watch [NumPy Tutorial for Beginners (freeCodeCamp)](https://www.youtube.com/watch?v=QUT1VHiLmmI)
   - Full 1-hour tutorial
   - Code along in Jupyter notebook
   - Topics: Array creation, indexing, slicing, operations
5. Read [NumPy Quickstart Tutorial](https://numpy.org/doc/stable/user/quickstart.html)
   - Focus on: array attributes, array creation, basic operations
   - Try every example in your own notebook
6. Practice NumPy operations
   - Create arrays using different methods (zeros, ones, arange, linspace)
   - Practice array indexing and slicing
   - Perform mathematical operations (sum, mean, std, dot product)
   - Work with 2D arrays (matrices)
   - Learn broadcasting basics

**Step 3: Code Quality & Best Practices** (Days 6-7)
7. Read [PEP 8 Style Guide](https://realpython.com/python-pep8/)
   - Learn naming conventions (snake_case for functions, PascalCase for classes)
   - Understand proper spacing and indentation
   - Learn when to use comments vs docstrings
8. Write documentation
   - Learn to write docstrings for functions and classes
   - Format: """Brief description. Detailed explanation. Args, Returns, Examples."""
   - Add docstrings to all previous project functions
9. Basic debugging practice
   - Learn to use print statements effectively
   - Practice using VS Code debugger (breakpoints, step through)
   - Understand reading error tracebacks from bottom to top
10. Introduction to testing
    - Learn basic unittest framework
    - Write simple test cases for a function
    - Run tests and understand assertions

**Step 4: Build Final Project** (Days 8-10)
11. Build Project 6: Data Analysis Utilities Package
    - Create proper package structure:
      ```
      data_utils/
        __init__.py
        file_handler.py  (CSV, JSON reading functions)
        stats.py         (mean, median, mode, std functions)
        cleaner.py       (remove nulls, duplicates)
      tests/
        test_file_handler.py
        test_stats.py
      README.md
      requirements.txt
      ```
    - Implement each module one at a time
    - Write docstrings for all functions
    - Create simple test cases
    - Test package by importing in separate notebook
    - Document usage in README.md

**Daily Schedule Recommendation:**
- Days 1-2: 2 hours Jupyter/Colab practice
- Days 3-5: 3 hours NumPy learning and practice each day
- Days 6-7: 2 hours code quality study + 1 hour refactoring old code
- Days 8-10: 4 hours project building each day

#### üõ†Ô∏è Hands-On Project:
6. **Data Analysis Utilities Package** (200 XP)
   - Create reusable Python package with utilities for data analysis
   - Include functions for file reading, basic stats, data cleaning
   - Write documentation and tests
   - Skills: Modules, packages, documentation, testing

> **üí° Tip:** Before proceeding to Module 2, ensure you can write Python scripts with functions and classes independently. This foundation is crucial for your AI engineering journey!

**‚úÖ Checkpoint Assessment:**
Before proceeding to Module 2, ensure you can:
- [ ] Write Python scripts with functions and classes independently
- [ ] Handle files (CSV, JSON) and errors gracefully
- [ ] Use OOP to model real-world problems
- [ ] Navigate Jupyter Notebooks comfortably
- [ ] Debug code using print statements and debugger
- [ ] Read and understand Python error messages

**Module 1 Completion:** 2,000 XP earned üéâ

**Progress:** `[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë] 50%`

[‚Üë Back to Top](#-table-of-contents)

---

## Module 2: Mathematics for AI

**Duration:** 2-3 weeks | **‚ö° XP Reward:** 1,500 XP

### Week 6-7: Essential Math Foundations

#### Why Math Matters for AI:
> Understanding the mathematics behind AI/ML algorithms will:
> - Help you debug when models don't work
> - Enable you to read research papers
> - Allow you to customize and improve algorithms
> - Make you a better engineer, not just a library user

#### üéØ Topics to Master:

**Linear Algebra:**
- [ ] Scalars, vectors, matrices, tensors
- [ ] Matrix operations (addition, multiplication, transpose)
- [ ] Dot product and cross product
- [ ] Matrix inverse and determinants
- [ ] Eigenvalues and eigenvectors (conceptual understanding)
- [ ] Why: Used in neural networks, dimensionality reduction, data transformations

**Calculus:**
- [ ] Derivatives and partial derivatives
- [ ] Chain rule
- [ ] Gradients
- [ ] Why: Backpropagation and optimization in neural networks

**Probability & Statistics:**
- [ ] Probability fundamentals (events, conditional probability)
- [ ] Bayes' theorem
- [ ] Distributions (normal, binomial, Poisson)
- [ ] Mean, median, mode, variance, standard deviation
- [ ] Covariance and correlation
- [ ] Hypothesis testing basics
- [ ] Why: Understanding data, model evaluation, uncertainty

#### üìö Resources:

<details>
<summary><strong>Visual & Intuitive (HIGHLY RECOMMENDED)</strong></summary>

- [3Blue1Brown - Essence of Linear Algebra](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab) - FREE, beautiful visualization (15 videos, ~3 hours)
- [3Blue1Brown - Essence of Calculus](https://www.youtube.com/playlist?list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr) - FREE (12 videos, ~3 hours)
- **[Krish Naik Statistics in ML (43 videos)](https://www.youtube.com/playlist?list=PLZoTAELRMXVMhVyr3Ri9IQ-t5QPBtxzJO)** - **ESSENTIAL FOR ML**
  - Complete statistics coverage for machine learning
  - Practical examples and intuitive explanations
  - Covers all probability and statistics fundamentals
- [StatQuest Statistics Fundamentals](https://www.youtube.com/playlist?list=PLblh5JKOoLUK0FLuzwntyYI10UQFUhsY9) - FREE, fun and clear (20+ videos)

</details>

<details>
<summary><strong>Comprehensive Courses</strong></summary>

- [Mathematics for Machine Learning Specialization (Coursera)](https://www.coursera.org/specializations/mathematics-machine-learning) - FREE audit
  - Linear Algebra course
  - Multivariate Calculus course
  - PCA course

- [Khan Academy - Linear Algebra](https://www.khanacademy.org/math/linear-algebra) - FREE, interactive
- [Khan Academy - Statistics and Probability](https://www.khanacademy.org/math/statistics-probability) - FREE

</details>

**Books (Free PDFs):**
- [Mathematics for Machine Learning (Deisenroth et al.)](https://mml-book.github.io/) - FREE book
- [Seeing Theory - Visual Probability and Statistics](https://seeing-theory.brown.edu/) - Interactive visualizations

**Python Implementation:**
- [NumPy for Linear Algebra](https://numpy.org/doc/stable/reference/routines.linalg.html)
- Practice implementing math concepts in NumPy

#### üìã Step-by-Step Learning Path:

**Step 1: Linear Algebra Foundations** (Days 1-5)
1. Watch [3Blue1Brown - Essence of Linear Algebra](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab)
   - Watch all 15 videos (~3 hours total, spread over 5 days)
   - Day 1: Videos 1-3 (Vectors, linear combinations, span)
   - Day 2: Videos 4-6 (Matrix multiplication, determinants)
   - Day 3: Videos 7-9 (Inverse matrices, column space, null space)
   - Day 4: Videos 10-12 (Dot products, cross products)
   - Day 5: Videos 13-15 (Change of basis, eigenvectors, eigenvalues)
   - After each video, take notes on key concepts
   - Try to visualize concepts in your mind
2. Implement concepts in NumPy
   - Create vectors and matrices using np.array()
   - Practice matrix multiplication with np.dot() and @ operator
   - Calculate determinants with np.linalg.det()
   - Find eigenvalues with np.linalg.eig()
   - Save all implementations in `math_practice/linear_algebra.ipynb`

**Step 2: Calculus Essentials** (Days 6-9)
3. Watch [3Blue1Brown - Essence of Calculus](https://www.youtube.com/playlist?list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr)
   - Watch all 12 videos (~3 hours total, spread over 4 days)
   - Day 6: Videos 1-3 (Derivatives, paradoxes, derivative formulas)
   - Day 7: Videos 4-6 (Chain rule, product rule)
   - Day 8: Videos 7-9 (Implicit differentiation, limits)
   - Day 9: Videos 10-12 (Integration, area under curves)
   - Focus on understanding derivatives and gradients (most important for ML)
4. Practice calculus in Python
   - Use SymPy library for symbolic math
   - Calculate derivatives of simple functions
   - Understand: derivative tells you the slope/rate of change
   - This is crucial for gradient descent in ML

**Step 3: Statistics & Probability** (Days 10-15)
5. Watch [Krish Naik Statistics in ML Playlist](https://www.youtube.com/playlist?list=PLZoTAELRMXVMhVyr3Ri9IQ-t5QPBtxzJO)
   - 43 videos covering all essential statistics
   - Watch 7-8 videos per day over 6 days
   - Days 10-11: Descriptive statistics (mean, median, mode, variance, std)
   - Days 12-13: Probability basics, distributions (normal, binomial)
   - Days 14: Correlation, covariance, hypothesis testing
   - Day 15: Bayes theorem, conditional probability
   - Take detailed notes - statistics is CRITICAL for ML
6. Alternative/Supplement: Watch [StatQuest](https://www.youtube.com/playlist?list=PLblh5JKOoLUK0FLuzwntyYI10UQFUhsY9)
   - Great for reinforcing concepts with different explanations
   - Watch videos on topics you find confusing
   - StatQuest makes complex topics simple and fun
7. Implement statistical functions in NumPy
   - Calculate mean, median, mode from scratch
   - Compute variance and standard deviation
   - Generate random numbers from different distributions
   - Calculate correlation between variables
   - Save in `math_practice/statistics.ipynb`

**Step 4: Optional Deep Dive** (If Time Permits)
8. Start [Mathematics for Machine Learning Specialization (Coursera)](https://www.coursera.org/specializations/mathematics-machine-learning)
   - Audit for FREE - don't pay for certificate
   - Focus on Linear Algebra course if you want more depth
   - This is optional but highly valuable
9. Use [Khan Academy](https://www.khanacademy.org/math/linear-algebra) for extra practice
   - Do practice exercises for topics you find difficult
   - Interactive practice helps reinforce learning

**Step 5: Hands-On Math Projects** (Days 16-20)
10. Build Project 7: Linear Algebra Visualizer
    - Use matplotlib to visualize vectors in 2D space
    - Show vector addition and subtraction
    - Visualize matrix transformations (rotation, scaling, shearing)
    - Plot before and after transformation
    - Code all visualizations yourself
11. Build Project 8: Statistical Analysis Tool
    - Implement statistical functions from scratch (don't use built-ins)
    - Create functions: calculate_mean(), calculate_variance(), etc.
    - Compare your results with NumPy/SciPy to verify correctness
    - Generate data from normal, binomial distributions
    - Create histograms and probability plots
    - Calculate and visualize correlation matrices

**Daily Schedule Recommendation:**
- Days 1-5: 1.5 hours Linear Algebra videos + 1 hour NumPy practice
- Days 6-9: 1.5 hours Calculus videos + 1 hour practice
- Days 10-15: 2 hours Statistics videos + 1 hour implementation
- Days 16-20: 4 hours project building each day

**Key Study Tips:**
- Don't try to memorize formulas - understand concepts
- Focus on: What does this do? Why does it matter for ML?
- Implement everything in NumPy for practical skills
- It's okay to not understand everything perfectly
- You'll learn more when you apply this to actual ML problems

#### üõ†Ô∏è Hands-On Projects:

7. **Linear Algebra Visualizer** (200 XP)
   - Create visualizations of vector operations, transformations
   - Use matplotlib to plot vectors, matrices
   - Skills: Linear algebra, NumPy, matplotlib

8. **Statistical Analysis Tool** (250 XP)
   - Implement statistical functions from scratch (mean, std, correlation)
   - Compare with NumPy/SciPy implementations
   - Generate random data from different distributions
   - Skills: Statistics, NumPy, SciPy

> **üí° Practical Tip:** Don't aim for mathematical perfection. Aim for:
> - Conceptual understanding (what does it do?)
> - Intuition (why does it matter for ML?)
> - Ability to implement using NumPy (practical skill)

**‚úÖ Checkpoint Assessment:**
Before proceeding, ensure you understand:
- [ ] What a matrix multiplication represents
- [ ] How gradients relate to optimization
- [ ] What correlation means and doesn't mean
- [ ] Basic probability concepts (P(A|B), independence)
- [ ] How to compute these operations in NumPy

**Module 2 Completion:** 1,500 XP earned üéâ

**Progress:** `[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë] 60%`

[‚Üë Back to Top](#-table-of-contents)

---

## Module 3: Data Manipulation & Analysis

**Duration:** 3-4 weeks | **‚ö° XP Reward:** 2,500 XP

### Week 8-10: NumPy & Pandas Mastery

#### üéØ Topics to Master:

**NumPy Deep Dive:**
- [ ] Array creation and indexing
- [ ] Broadcasting
- [ ] Universal functions (ufuncs)
- [ ] Array operations and methods
- [ ] Random number generation
- [ ] Linear algebra operations
- [ ] File I/O with NumPy

**Pandas Fundamentals:**
- [ ] Series and DataFrames
- [ ] Reading data (CSV, Excel, JSON, SQL)
- [ ] Indexing and selecting data (loc, iloc)
- [ ] Filtering and querying
- [ ] Handling missing data
- [ ] Data type conversions
- [ ] Grouping and aggregation
- [ ] Merging, joining, concatenating
- [ ] Pivot tables and cross-tabulations
- [ ] Time series basics
- [ ] Data cleaning techniques

#### üìö Resources:

<details>
<summary><strong>Primary Course</strong></summary>

- **[Your Udemy: Python for Data Science and ML Bootcamp](https://www.udemy.com/course/python-for-data-science-and-machine-learning-bootcamp/)** - NumPy & Pandas sections
  - Sections 2-5 cover NumPy and Pandas comprehensively

</details>

<details>
<summary><strong>Free Video Tutorials</strong></summary>

- [NumPy Tutorial for Beginners (Keith Galli)](https://www.youtube.com/watch?v=QUT1VHiLmmI) - 1 hour
- [Complete Python Pandas Data Science Tutorial (Keith Galli)](https://www.youtube.com/watch?v=vmEHCJofslg) - 1 hour
- [Pandas for Data Analysis (Corey Schafer)](https://www.youtube.com/playlist?list=PL-osiE80TeTsWmV9i9c58mdDCSskIFdDS) - Series of videos

</details>

<details>
<summary><strong>Interactive Learning</strong></summary>

- [Kaggle - Pandas Course](https://www.kaggle.com/learn/pandas) - FREE, 4 hours
- [NumPy Exercises (GitHub)](https://github.com/rougier/numpy-100) - 100 NumPy exercises

</details>

**Official Documentation:**
- [NumPy Documentation](https://numpy.org/doc/)
- [Pandas Documentation](https://pandas.pydata.org/docs/)
- [Pandas Cheat Sheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf) - Print this!

**Practice Datasets:**
- [Kaggle Datasets](https://www.kaggle.com/datasets) - Thousands of free datasets
- [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php)
- [Data.gov](https://www.data.gov/) - US government open data

#### üìã Step-by-Step Learning Path:

**Step 1: NumPy Deep Dive** (Days 1-5)
1. Watch [NumPy Tutorial for Beginners (Keith Galli)](https://www.youtube.com/watch?v=QUT1VHiLmmI)
   - Full 1-hour tutorial
   - Code along in a new Jupyter notebook
   - Topics: Array creation, indexing, slicing, operations, broadcasting
2. Complete [100 NumPy Exercises](https://github.com/rougier/numpy-100)
   - Start with exercises 1-30 (basic operations)
   - Do 10 exercises per day over 3 days
   - Don't look at solutions immediately - try for 10 minutes first
   - Focus on: array creation, indexing, boolean masking, operations
3. Practice NumPy intensively
   - Create arrays using: zeros, ones, arange, linspace, random
   - Master slicing: arr[start:stop:step], 2D slicing
   - Boolean indexing: arr[arr > 5]
   - Array operations: reshape, transpose, concatenate, stack
   - Universal functions: np.sqrt(), np.exp(), np.sin()
   - Save all practice in `numpy_practice/exercises.ipynb`

**Step 2: Pandas Fundamentals** (Days 6-12)
4. Watch Udemy DS & ML Bootcamp - Sections 2-5
   - Section 2: NumPy review (1-2 hours)
   - Section 3: Pandas Introduction (3-4 hours)
   - Section 4: Pandas Operations (3-4 hours)
   - Section 5: Pandas Advanced (2-3 hours)
   - Complete all coding exercises in each section
   - Create separate notebooks for each section
5. Alternative: Watch [Complete Pandas Tutorial (Keith Galli)](https://www.youtube.com/watch?v=vmEHCJofslg)
   - 1-hour comprehensive tutorial
   - Code along for every example
   - Practice reading CSV, filtering, grouping
6. Complete [Kaggle Pandas Course](https://www.kaggle.com/learn/pandas)
   - 6 lessons, approximately 4 hours total
   - Lesson 1: Creating, Reading, and Writing
   - Lesson 2: Indexing, Selecting & Assigning
   - Lesson 3: Summary Functions and Maps
   - Lesson 4: Grouping and Sorting
   - Lesson 5: Data Types and Missing Values
   - Lesson 6: Renaming and Combining
   - Complete all exercises at end of each lesson
   - Earn the Pandas certificate
7. Watch [Corey Schafer Pandas Series](https://www.youtube.com/playlist?list=PL-osiE80TeTsWmV9i9c58mdDCSskIFdDS)
   - 10 videos covering different Pandas topics
   - Great for reinforcing concepts with different examples
   - Focus on videos about groupby, merging, time series

**Step 3: Intensive Pandas Practice** (Days 13-15)
8. Download [Pandas Cheat Sheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf)
   - Print it or keep it open while practicing
   - Reference frequently until concepts stick
9. Practice on real datasets
   - Go to [Kaggle Datasets](https://www.kaggle.com/datasets)
   - Download 3-5 different CSV datasets (sales, customer, product data)
   - For each dataset practice:
     - Reading: pd.read_csv()
     - Exploring: .head(), .info(), .describe(), .shape
     - Filtering: df[df['column'] > value]
     - Selecting: .loc[], .iloc[]
     - Grouping: .groupby().agg()
     - Handling nulls: .isnull(), .fillna(), .dropna()
10. Master these essential operations:
    - Loading data: read_csv, read_excel, read_json
    - Selection: df['col'], df[['col1', 'col2']], df.loc[], df.iloc[]
    - Filtering: df[df.age > 30], df.query('age > 30')
    - Sorting: df.sort_values()
    - Grouping: df.groupby('category')['sales'].sum()
    - Missing data: .isnull(), .fillna(0), .dropna()
    - Merging: pd.merge(), pd.concat()
    - Pivot tables: df.pivot_table()

**Step 4: Advanced Pandas Techniques** (Days 16-18)
11. Learn merging and joining
    - Practice pd.merge() with different join types (inner, outer, left, right)
    - Use pd.concat() to combine dataframes
    - Understand when to use merge vs concat vs join
12. Time series operations
    - Convert strings to datetime: pd.to_datetime()
    - Set datetime as index: df.set_index('date')
    - Resample time series: df.resample('M').mean()
    - Calculate rolling averages: df.rolling(window=7).mean()
13. Apply custom functions
    - Use .apply() for row/column operations
    - Create lambda functions for quick transformations
    - Use .map() for element-wise operations

**Step 5: Build Data Projects** (Days 19-25)
14. Build Project 9: Sales Data Analyzer
    - Download a sales dataset (or use sample data)
    - Clean the data: handle missing values, fix data types
    - Calculate: monthly revenue, top 10 products, regional performance
    - Create pivot table for month x region sales
    - Export cleaned data and summary statistics
    - Document all steps in markdown cells
15. Build Project 10: COVID-19 Data Dashboard
    - Download COVID-19 time series data from Kaggle
    - Parse dates and set as index
    - Calculate daily cases (difference from previous day)
    - Calculate 7-day moving average
    - Calculate week-over-week growth rates
    - Compare 5 different countries
    - Create summary tables and export to CSV
16. Build Project 11: E-commerce Data Processor
    - Create or download: customers.csv, orders.csv, products.csv
    - Merge all three datasets on appropriate keys
    - Calculate customer lifetime value (total spending per customer)
    - Identify top 10 customers by revenue
    - Find top 10 products by quantity sold
    - Handle data quality issues (duplicates, missing values)
    - Export final merged dataset

**Daily Schedule Recommendation:**
- Days 1-5: 3 hours NumPy practice daily
- Days 6-12: 3 hours Pandas learning + exercises daily
- Days 13-15: 4 hours intensive Pandas practice with datasets
- Days 16-18: 3 hours advanced techniques practice
- Days 19-25: 4-5 hours project building each day

**Weekly Practice Goal:**
- Spend 1 hour daily exploring a new Kaggle dataset
- Ask yourself: "What insights can I find?"
- Practice the entire workflow: load ‚Üí clean ‚Üí analyze ‚Üí summarize

#### üõ†Ô∏è Hands-On Projects:

9. **Sales Data Analyzer** (300 XP)
   - Load and clean sales dataset (CSV with missing values)
   - Calculate monthly revenue, top products, regional performance
   - Handle missing data appropriately
   - Export cleaned data and summary statistics
   - Skills: Pandas, data cleaning, aggregation, file I/O

10. **COVID-19 Data Dashboard (Console)** (400 XP)
    - Download COVID-19 time series data
    - Calculate daily/weekly cases, growth rates, moving averages
    - Compare multiple countries/regions
    - Generate summary reports
    - Skills: Pandas time series, filtering, aggregation, calculations

11. **E-commerce Data Processor** (400 XP)
    - Merge customer, orders, and products datasets
    - Calculate customer lifetime value (CLV)
    - Identify top customers and products
    - Handle data quality issues
    - Skills: Merging, aggregation, complex calculations

> **üí° Weekly Practice:** Spend 1 hour daily on Kaggle datasets. Try to answer: "What insights can I find in this data?"

**‚úÖ Checkpoint Assessment:**
Can you confidently:
- [ ] Load data from multiple formats into Pandas?
- [ ] Clean messy data (missing values, duplicates, types)?
- [ ] Filter, sort, and select subsets of data?
- [ ] Group data and calculate aggregations?
- [ ] Merge multiple datasets together?
- [ ] Perform date/time operations on time series?
- [ ] Export cleaned data for further analysis?

**Module 3 Completion:** 2,500 XP earned üéâ

**Progress:** `[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë] 75%`

[‚Üë Back to Top](#-table-of-contents)

---

## Module 4: Data Visualization & Exploratory Data Analysis

**Duration:** 2-3 weeks | **‚ö° XP Reward:** 2,000 XP

### Week 11-13: Visual Storytelling with Data

#### üéØ Topics to Master:

**Matplotlib:**
- [ ] Figure and axes objects
- [ ] Line plots, scatter plots, bar charts
- [ ] Histograms and distributions
- [ ] Subplots and layouts
- [ ] Customization (colors, labels, legends, titles)
- [ ] Saving figures

**Seaborn:**
- [ ] Statistical plots (histograms, KDE, box plots)
- [ ] Relationship plots (scatter, line, regression)
- [ ] Categorical plots (bar, count, box, violin)
- [ ] Distribution plots
- [ ] Heatmaps and correlation matrices
- [ ] Pair plots
- [ ] Styling and themes

**Plotly (Optional but Recommended):**
- [ ] Interactive plots
- [ ] Plotly Express for quick visualizations
- [ ] Dashboard basics

**Exploratory Data Analysis (EDA):**
- [ ] Understanding your data (shape, types, missing values)
- [ ] Univariate analysis
- [ ] Bivariate and multivariate analysis
- [ ] Identifying patterns and outliers
- [ ] Correlation analysis
- [ ] Feature distributions
- [ ] Asking the right questions

#### üìö Resources:

<details>
<summary><strong>Primary Course</strong></summary>

- **[Your Udemy: Python for Data Science and ML Bootcamp](https://www.udemy.com/course/python-for-data-science-and-machine-learning-bootcamp/)** - Data Visualization sections

- **Krish Naik EDA Resources:**
  - Various EDA technique videos in his playlists
  - Practical walkthroughs of real datasets
  - Industry-standard EDA practices

</details>

<details>
<summary><strong>Free Video Tutorials</strong></summary>

- [Matplotlib Tutorial Series (Corey Schafer)](https://www.youtube.com/playlist?list=PL-osiE80TeTvipOqomVEeZ1HRrcEvtZB_) - 10 videos
- [Seaborn Tutorial (Keith Galli)](https://www.youtube.com/watch?v=6GUZXDef2U0) - 1 hour
- [Complete Plotly Tutorial (Charming Data)](https://www.youtube.com/watch?v=hEPoto5xp3k) - 1 hour

</details>

<details>
<summary><strong>Interactive Learning</strong></summary>

- [Kaggle - Data Visualization](https://www.kaggle.com/learn/data-visualization) - FREE, 4 hours
- [Kaggle - Data Cleaning](https://www.kaggle.com/learn/data-cleaning) - FREE, 4 hours

</details>

**Best Practices:**
- [Data Visualization Best Practices (Kaggle)](https://www.kaggle.com/code/residentmario/best-practices-for-data-visualization)
- [Seaborn Tutorial (Official)](https://seaborn.pydata.org/tutorial.html)

**Inspiration:**
- [Storytelling with Data](https://www.storytellingwithdata.com/) - Blog with great examples
- [Python Graph Gallery](https://python-graph-gallery.com/) - Hundreds of chart examples
- [Kaggle Notebooks](https://www.kaggle.com/code) - Search "EDA" for inspiration

#### üìã Step-by-Step Learning Path:

**Step 1: Matplotlib Fundamentals** (Days 1-5)
1. Complete Udemy DS & ML Bootcamp - Data Visualization sections
   - Matplotlib section (2-3 hours)
   - Code along with every plot example
   - Save plots in `visualizations/matplotlib_practice/`
2. Watch [Matplotlib Tutorial Series (Corey Schafer)](https://www.youtube.com/playlist?list=PL-osiE80TeTvipOqomVEeZ1HRrcEvtZB_)
   - All 10 videos (approximately 2 hours total)
   - Day 1: Videos 1-3 (basics, line plots, bar charts)
   - Day 2: Videos 4-6 (histograms, scatter plots, time series)
   - Day 3: Videos 7-10 (subplots, legends, customization, saving)
   - Code every example in your own notebook
3. Practice creating different plot types
   - Line plot: plt.plot(x, y)
   - Scatter plot: plt.scatter(x, y)
   - Bar chart: plt.bar(categories, values)
   - Histogram: plt.hist(data, bins=20)
   - Multiple plots: plt.subplot(2, 2, 1)
   - Customize: colors, labels, titles, legends, grid
4. Learn figure and axes objects
   - Understand: fig, ax = plt.subplots()
   - Use ax.plot() instead of plt.plot() for more control
   - Create multi-panel figures
   - Save figures: plt.savefig('plot.png', dpi=300, bbox_inches='tight')

**Step 2: Seaborn for Statistical Plots** (Days 6-10)
5. Watch [Seaborn Tutorial (Keith Galli)](https://www.youtube.com/watch?v=6GUZXDef2U0)
   - 1-hour comprehensive tutorial
   - Code along for all examples
   - Topics: distributions, relationships, categorical data
6. Complete Udemy DS & ML Bootcamp - Seaborn section
   - Learn different plot types and when to use them
   - Practice customizing seaborn plots
7. Read [Official Seaborn Tutorial](https://seaborn.pydata.org/tutorial.html)
   - Work through examples for each plot type
   - Save examples in `visualizations/seaborn_practice/`
8. Master these Seaborn plot types:
   - Distribution: sns.histplot(), sns.kdeplot(), sns.boxplot(), sns.violinplot()
   - Categorical: sns.barplot(), sns.countplot(), sns.boxplot()
   - Relationships: sns.scatterplot(), sns.lineplot(), sns.regplot()
   - Matrix: sns.heatmap() for correlation matrices
   - Multiple variables: sns.pairplot() for all pairwise relationships
9. Practice Seaborn styling
   - Set themes: sns.set_theme(style='darkgrid')
   - Color palettes: sns.color_palette('husl', 10)
   - Context: sns.set_context('talk') for presentations

**Step 3: Interactive Visualizations with Plotly** (Days 11-12)
10. Watch [Complete Plotly Tutorial (Charming Data)](https://www.youtube.com/watch?v=hEPoto5xp3k)
    - 1-hour tutorial on Plotly basics
    - Learn Plotly Express for quick visualizations
11. Practice creating interactive plots
    - Import: import plotly.express as px
    - Line plot: px.line(df, x='date', y='value')
    - Scatter: px.scatter(df, x='x', y='y', color='category')
    - Bar: px.bar(df, x='category', y='count')
    - All plots are interactive by default (zoom, hover, pan)
12. Learn Plotly advantages
    - Interactive tooltips show exact values
    - Can zoom and pan
    - Great for presentations and dashboards
    - Export as HTML for sharing

**Step 4: EDA Methodology** (Days 13-15)
13. Complete [Kaggle - Data Visualization Course](https://www.kaggle.com/learn/data-visualization)
    - 4 hours, covers seaborn and best practices
    - Complete all exercises
    - Earn the certificate
14. Complete [Kaggle - Data Cleaning Course](https://www.kaggle.com/learn/data-cleaning)
    - 4 hours, essential for EDA
    - Learn to handle missing data, inconsistent data
    - Complete all exercises
15. Study EDA methodology
    - Step 1: Understand data (shape, columns, types, nulls)
    - Step 2: Univariate analysis (distribution of each variable)
    - Step 3: Bivariate analysis (relationships between pairs)
    - Step 4: Multivariate analysis (3+ variables together)
    - Step 5: Identify patterns, outliers, anomalies
    - Step 6: Document insights and findings
16. Browse [Kaggle Notebooks](https://www.kaggle.com/code)
    - Search for "EDA" to find excellent examples
    - Study 5-10 highly-voted EDA notebooks
    - Notice the structure and flow they follow
    - Save favorites for reference

**Step 5: Build EDA Projects** (Days 16-21)
17. Build Project 12: Titanic Dataset EDA
    - Download Titanic dataset from Kaggle
    - Start with data exploration:
      - df.head(), df.info(), df.describe()
      - Check missing values: df.isnull().sum()
    - Univariate analysis:
      - Age distribution (histogram)
      - Survival rate (count plot)
      - Passenger class distribution (bar chart)
    - Bivariate analysis:
      - Survival by gender (grouped bar chart)
      - Survival by class (grouped bar chart)
      - Age vs survival (box plot, violin plot)
      - Fare distribution by class (box plot)
    - Multivariate analysis:
      - Survival by class and gender (grouped bar)
      - Correlation heatmap of numeric features
    - Create at least 10+ meaningful visualizations
    - Document findings in markdown cells
    - Answer: What factors affected survival most?
18. Build Project 13: Housing Prices Analysis
    - Download Boston/California/Ames housing dataset
    - Data exploration and cleaning
    - Univariate analysis: distribution of price and all features
    - Bivariate analysis:
      - Price vs square footage (scatter + regression line)
      - Price vs number of bedrooms (box plot)
      - Price vs location (if available)
    - Correlation analysis:
      - Calculate correlation matrix
      - Create heatmap with sns.heatmap()
      - Identify top 5 features correlated with price
    - Identify outliers:
      - Box plots for all numeric features
      - Scatter plots highlighting outliers
    - Document all insights and patterns found
19. Build Project 14: Personal Finance Dashboard
    - Create or download sample financial transaction data
    - If creating: make CSV with date, category, amount, type (income/expense)
    - Time series analysis:
      - Monthly income vs expenses (line plot)
      - Spending by category over time (stacked area chart)
    - Categorical analysis:
      - Spending by category (pie chart or bar chart)
      - Income sources breakdown
    - Create interactive visualizations with Plotly:
      - Interactive line charts with hover data
      - Interactive bar charts
    - Generate PDF report with matplotlib (save multiple figures)
    - Optional: Create simple HTML dashboard

**Daily Schedule Recommendation:**
- Days 1-5: 3 hours Matplotlib learning + practice
- Days 6-10: 3 hours Seaborn learning + practice
- Days 11-12: 2 hours Plotly learning + practice
- Days 13-15: 3 hours EDA methodology study + Kaggle courses
- Days 16-21: 5 hours daily on EDA projects

**EDA Checklist for Every Project:**
1. Data overview: shape, columns, types, memory usage
2. Missing values: identify and visualize
3. Summary statistics: describe() for numeric features
4. Target variable: distribution and balance
5. Numeric features: histograms, box plots
6. Categorical features: count plots, bar charts
7. Correlations: heatmap and top correlations
8. Outliers: identification and visualization
9. Insights: document findings in markdown
10. Conclusions: summarize key patterns

#### üõ†Ô∏è Hands-On Projects:

12. **Titanic Dataset EDA** (300 XP)
    - Complete exploratory analysis of Titanic dataset
    - Survival rates by class, gender, age
    - Create 10+ meaningful visualizations
    - Document findings and insights
    - Skills: Pandas, matplotlib, seaborn, EDA methodology

13. **Housing Prices Analysis** (400 XP)
    - Analyze housing dataset (Boston/California/Ames)
    - Univariate and bivariate analysis
    - Correlation analysis and heatmaps
    - Price distributions by features
    - Identify outliers and patterns
    - Skills: Advanced EDA, statistical analysis, visualization

14. **Personal Finance Dashboard** (400 XP)
    - Create or use sample financial transaction data
    - Monthly spending by category
    - Income vs expenses trends
    - Interactive visualizations with Plotly
    - Generate PDF report with matplotlib
    - Skills: Time series viz, Plotly, report generation

> **üí° EDA Best Practices:**
> 1. Start with basic questions: shape, dtypes, missing values
> 2. Understand target variable distribution
> 3. Check for class imbalance
> 4. Visualize distributions of all features
> 5. Identify correlations and relationships
> 6. Look for outliers and anomalies
> 7. Document insights in markdown cells

**‚úÖ Checkpoint Assessment:**
Can you:
- [ ] Create professional-looking plots with matplotlib?
- [ ] Use seaborn for statistical visualizations?
- [ ] Conduct systematic exploratory data analysis?
- [ ] Identify data quality issues through visualization?
- [ ] Tell a story with your visualizations?
- [ ] Choose appropriate plot types for different data?
- [ ] Customize plots for clarity and aesthetics?

**Module 4 Completion:** 2,000 XP earned üéâ

**Progress:** `[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë] 85%`

[‚Üë Back to Top](#-table-of-contents)

---

## Module 5: Version Control & Development Tools

**Duration:** 1 week | **‚ö° XP Reward:** 1,000 XP

### Week 14: Git, GitHub, and Professional Workflow

#### üéØ Topics to Master:

**Git Basics:**
- [ ] Git installation and configuration
- [ ] Repository initialization
- [ ] Staging and committing changes
- [ ] Viewing history and diffs
- [ ] Branching and merging
- [ ] .gitignore files
- [ ] Undoing changes

**GitHub:**
- [ ] Creating repositories
- [ ] Pushing and pulling
- [ ] README.md files and documentation
- [ ] GitHub Pages for portfolio
- [ ] Collaborating with others (basics)
- [ ] Issues and project management

**Development Best Practices:**
- [ ] Project structure and organization
- [ ] Virtual environments (conda, venv)
- [ ] Requirements.txt files
- [ ] Code documentation
- [ ] Jupyter notebook best practices

**Bonus Database Knowledge:**
- [ ] MongoDB basics (NoSQL)
- [ ] MySQL fundamentals (SQL)
- [ ] When to use SQL vs NoSQL

#### üìö Resources:

<details>
<summary><strong>Git & GitHub</strong></summary>

- [Git and GitHub for Beginners (freeCodeCamp)](https://www.youtube.com/watch?v=RGOj5yH7evk) - 1 hour
- [Git Tutorial (Corey Schafer)](https://www.youtube.com/playlist?list=PL-osiE80TeTuRUfjRe54Eea17-YfnOOAx) - Video series
- [GitHub Skills](https://skills.github.com/) - Interactive tutorials, FREE
- [Pro Git Book](https://git-scm.com/book/en/v2) - FREE online book

</details>

<details>
<summary><strong>Interactive Practice</strong></summary>

- [Learn Git Branching](https://learngitbranching.js.org/) - Visual interactive tutorial
- [GitHub Learning Lab](https://lab.github.com/) - Hands-on courses

</details>

**Portfolio Building:**
- [How to Build a Data Science Portfolio (DataQuest)](https://www.dataquest.io/blog/build-a-data-science-portfolio/)
- [Creating a GitHub Portfolio](https://towardsdatascience.com/how-to-create-a-compelling-github-portfolio-a229e7472a92)

**Databases (Bonus):**
- MongoDB basics tutorials
- MySQL fundamentals tutorials

#### üìã Step-by-Step Learning Path:

**Step 1: Git Installation & Setup** (Day 1)
1. Install Git on your system
   - Windows: Download from [git-scm.com](https://git-scm.com/)
   - Mac: Install via Homebrew `brew install git` or Xcode
   - Linux: `sudo apt-get install git` or equivalent
2. Configure Git with your information
   - Open terminal/command prompt
   - Set name: `git config --global user.name "Your Name"`
   - Set email: `git config --global user.email "your.email@example.com"`
   - Check config: `git config --list`
3. Create GitHub account
   - Sign up at [github.com](https://github.com)
   - Set up SSH keys or use HTTPS (SSH recommended for ease)
   - Follow [GitHub SSH setup guide](https://docs.github.com/en/authentication/connecting-to-github-with-ssh)

**Step 2: Learn Git Basics** (Days 2-3)
4. Watch [Git and GitHub for Beginners (freeCodeCamp)](https://www.youtube.com/watch?v=RGOj5yH7evk)
   - 1-hour comprehensive tutorial
   - Follow along with every command
   - Create a test repository and practice
5. Practice essential Git commands
   - Initialize: `git init`
   - Check status: `git status`
   - Stage files: `git add filename` or `git add .`
   - Commit: `git commit -m "Your message"`
   - View history: `git log` or `git log --oneline`
   - View changes: `git diff`
6. Create your first local repository
   - Create a folder: `mkdir my_first_repo`
   - Navigate: `cd my_first_repo`
   - Initialize: `git init`
   - Create a file: `echo "# My First Repo" > README.md`
   - Stage: `git add README.md`
   - Commit: `git commit -m "Initial commit"`

**Step 3: Learn GitHub & Remote Repositories** (Days 4-5)
7. Complete [GitHub Skills](https://skills.github.com/) interactive tutorials
   - "Introduction to GitHub" course
   - "Communicate using Markdown" course
   - Practice creating repositories
8. Push your local repository to GitHub
   - Create new repository on GitHub (don't initialize with README)
   - Copy the remote URL
   - Add remote: `git remote add origin <URL>`
   - Push: `git push -u origin main` (or master)
9. Practice the Git workflow
   - Make changes to files locally
   - Check status: `git status`
   - Stage changes: `git add .`
   - Commit: `git commit -m "Descriptive message"`
   - Push to GitHub: `git push`
   - Refresh GitHub page to see changes
10. Learn to write good README.md files
    - Use markdown syntax: headers, lists, code blocks, links
    - Include: project title, description, installation, usage, examples
    - Add badges for style (optional)
    - Study examples from popular GitHub repos

**Step 4: Branching, .gitignore & Best Practices** (Day 6)
11. Complete [Learn Git Branching](https://learngitbranching.js.org/)
    - Visual, interactive tutorial
    - Complete "Main" levels 1-4 (Introduction Sequence)
    - Understand branching and merging
12. Practice branching
    - Create branch: `git branch feature-name`
    - Switch branch: `git checkout feature-name` or `git switch feature-name`
    - Make changes and commit on branch
    - Switch back: `git checkout main`
    - Merge: `git merge feature-name`
13. Create .gitignore files
    - Create `.gitignore` in repository root
    - Add patterns to ignore: `*.pyc`, `__pycache__/`, `.ipynb_checkpoints/`, `.env`
    - Use [gitignore.io](https://www.toptal.com/developers/gitignore) to generate templates
    - Common for Python/Data Science:
      ```
      __pycache__/
      *.pyc
      .ipynb_checkpoints/
      .env
      data/
      *.csv
      *.xlsx
      ```
14. Learn requirements.txt
    - Create virtual environment: `conda create -n myenv python=3.10`
    - Activate: `conda activate myenv`
    - Install packages: `pip install pandas numpy matplotlib`
    - Generate requirements: `pip freeze > requirements.txt`
    - Others can install: `pip install -r requirements.txt`

**Step 5: Build Professional Portfolio** (Days 7-10)
15. Build Project 15: Portfolio Website with GitHub Pages
    - Create repository named `<username>.github.io`
    - Add index.html or use Jekyll/Hugo for static site
    - Alternative: Create README.md for profile repository
    - Include:
      - Brief introduction and photo
      - Skills and technologies
      - Featured projects with links
      - Contact information
    - Push to GitHub - site goes live at `<username>.github.io`
16. Build Project 16: Organize All Previous Projects
    - Create individual repository for each project (Projects 1-14)
    - For each project:
      - Initialize git repository
      - Add comprehensive README.md with:
        - Project title and description
        - Technologies used
        - Installation/Setup instructions
        - Usage examples with screenshots
        - Results and insights (for data projects)
        - Future improvements
      - Create requirements.txt (if uses external packages)
      - Organize file structure professionally:
        ```
        project_name/
          README.md
          requirements.txt
          data/ (add to .gitignore if large)
          notebooks/
          scripts/
          output/
          .gitignore
        ```
      - Add code comments and docstrings
      - Commit with meaningful messages
      - Push to GitHub
17. Create profile README
    - Create repository with same name as username
    - Add README.md that displays on your profile
    - Include: intro, skills, current learning, featured projects
    - Use GitHub stats badges (optional but cool)
    - Pin your best 6 repositories on profile

**Daily Schedule Recommendation:**
- Day 1: 2 hours (installation, setup, configuration)
- Days 2-3: 3 hours each (Git basics learning and practice)
- Days 4-5: 3 hours each (GitHub and remote repositories)
- Day 6: 3 hours (branching, best practices)
- Days 7-10: 4-5 hours each (portfolio building and organization)

**Git Best Practices:**
- Commit often with descriptive messages
- Use present tense: "Add feature" not "Added feature"
- Keep commits focused (one logical change per commit)
- Always pull before you push (if collaborating)
- Review changes with `git diff` before committing
- Use .gitignore to avoid committing unnecessary files
- Write clear README files for every project

#### üõ†Ô∏è Hands-On Projects:

15. **Build Your Portfolio Website** (300 XP)
    - Create a GitHub Pages website showcasing your projects
    - Include project descriptions, code snippets, visualizations
    - Write a compelling README for your main profile
    - Skills: Git, GitHub, markdown, documentation

16. **Organize All Previous Projects** (200 XP)
    - Create individual repositories for all 14 previous projects
    - Write comprehensive README files for each
    - Include requirements.txt, proper structure
    - Add comments and documentation to code
    - Skills: Git workflow, documentation, organization

> **üí° Daily Habit:** Commit code daily with meaningful messages. Push to GitHub at end of each work session.

**Portfolio Checklist:**
- [ ] GitHub profile README with introduction
- [ ] 15+ repositories with well-documented projects
- [ ] Consistent commit history (shows consistency)
- [ ] Clear project descriptions and results
- [ ] Requirements files for reproducibility
- [ ] Professional formatting and organization

**‚úÖ Checkpoint Assessment:**
Can you:
- [ ] Initialize a Git repository and make commits?
- [ ] Create and push repositories to GitHub?
- [ ] Write effective README files with markdown?
- [ ] Use .gitignore to exclude unnecessary files?
- [ ] Create branches and merge changes?
- [ ] Structure projects professionally?
- [ ] Document code and projects clearly?

**Module 5 Completion:** 1,000 XP earned üéâ

**Progress:** `[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 95%`

[‚Üë Back to Top](#-table-of-contents)

---

## üèÜ Capstone Project

**Duration:** 1-2 weeks | **‚ö° XP Reward:** 1,000 XP

### Complete Data Analysis Project: "Industry Dataset Analysis"

**üéØ Objective:** Demonstrate all beginner-level skills in one comprehensive project

**Requirements:**

1. **Choose a Real-World Dataset** (Examples):
   - [Airbnb Listings Data](https://www.kaggle.com/datasets) - Pricing analysis
   - [Retail Sales Data](https://www.kaggle.com/datasets) - Sales forecasting
   - [Healthcare Dataset](https://www.kaggle.com/datasets) - Patient analysis
   - [E-commerce Transactions](https://www.kaggle.com/datasets) - Customer behavior

2. **Project Components:**
   - [ ] Data collection and loading (multiple sources if possible)
   - [ ] Comprehensive data cleaning and preprocessing
   - [ ] Exploratory data analysis with 15+ visualizations
   - [ ] Statistical analysis and hypothesis testing
   - [ ] Feature engineering (create new meaningful features)
   - [ ] Business insights and recommendations
   - [ ] Professional Jupyter notebook with narrative
   - [ ] GitHub repository with complete documentation
   - [ ] README with project description, findings, and visuals

3. **Technical Requirements:**
   - Use Python, NumPy, Pandas, Matplotlib, Seaborn
   - Handle missing data appropriately
   - Create reusable functions for analysis
   - Include statistical tests where appropriate
   - Generate at least one automated report/dashboard

4. **Deliverables:**
   - Jupyter notebook (.ipynb) with full analysis
   - Python script (.py) version of analysis
   - HTML export of notebook for easy viewing
   - README.md with executive summary
   - Data dictionary explaining all features
   - requirements.txt for reproducibility

#### üìã Step-by-Step Learning Path:

**Step 1: Dataset Selection & Planning** (Days 1-2)
1. Choose your dataset from [Kaggle](https://www.kaggle.com/datasets)
   - Look for datasets with 10+ columns and 1000+ rows
   - Choose a domain you're interested in
   - Read dataset description and understand the context
   - Download the data and any supplementary files
2. Define your analysis goals
   - Write down 5-10 questions you want to answer
   - Example for Airbnb: "What factors influence listing price?"
   - Example for Retail: "What products sell best together?"
   - Document these in a project plan
3. Set up project structure
   - Create GitHub repository: `capstone-data-analysis`
   - Create folder structure:
     ```
     capstone-data-analysis/
       README.md
       requirements.txt
       data/
       notebooks/
         01_data_exploration.ipynb
         02_data_cleaning.ipynb
         03_eda.ipynb
         04_analysis.ipynb
       scripts/
       output/
         figures/
         reports/
       .gitignore
     ```
   - Initialize git and make initial commit

**Step 2: Data Loading & Initial Exploration** (Days 3-4)
4. Create `01_data_exploration.ipynb`
   - Import libraries: pandas, numpy, matplotlib, seaborn
   - Load data: `df = pd.read_csv('data/dataset.csv')`
   - Initial exploration:
     - `df.head(10)` - see first rows
     - `df.info()` - column types and null counts
     - `df.describe()` - statistical summary
     - `df.shape` - dimensions
     - Check for duplicates: `df.duplicated().sum()`
   - Document findings in markdown cells
5. Create data dictionary
   - List all columns with descriptions
   - Note data types and expected values
   - Identify potential issues
   - Save as `data_dictionary.md`

**Step 3: Data Cleaning** (Days 5-6)
6. Create `02_data_cleaning.ipynb`
   - Handle missing values:
     - Identify: `df.isnull().sum()`
     - Visualize: `sns.heatmap(df.isnull(), cbar=False)`
     - Decide strategy: drop, fill with mean/median/mode, forward fill
     - Document why you chose each approach
   - Remove duplicates: `df.drop_duplicates(inplace=True)`
   - Fix data types:
     - Convert to datetime: `pd.to_datetime(df['date'])`
     - Convert to categorical: `df['category'].astype('category')`
   - Handle outliers:
     - Identify with box plots and statistical methods
     - Decide: keep, remove, or cap
   - Create cleaned dataset: `df.to_csv('data/cleaned_data.csv', index=False)`
7. Create reusable cleaning functions
   - Write functions for common tasks
   - Example: `def handle_missing_numeric(df, column, method='mean')`
   - Save in `scripts/data_cleaning.py`
   - Import and use in notebook

**Step 4: Exploratory Data Analysis** (Days 7-10)
8. Create `03_eda.ipynb`
   - Load cleaned data
   - Univariate analysis:
     - Distribution of target variable (if applicable)
     - Histograms for all numeric features
     - Count plots for categorical features
     - Box plots to identify outliers
     - Create at least 5-7 univariate plots
   - Bivariate analysis:
     - Scatter plots for numeric pairs
     - Box plots: numeric by categorical
     - Bar plots: categorical relationships
     - Correlation heatmap for all numeric features
     - Create at least 6-8 bivariate plots
   - Multivariate analysis:
     - Pair plots for top features
     - Grouped bar charts
     - Faceted plots with seaborn FacetGrid
     - 3+ multivariate visualizations
   - Document insights after each visualization
9. Statistical analysis
   - Calculate correlations: `df.corr()`
   - Identify top correlations with target
   - Perform hypothesis tests if applicable
   - Document statistical findings

**Step 5: Feature Engineering & Advanced Analysis** (Days 11-12)
10. Create new features
    - Derive features from existing ones
    - Example: age from birth date, price per square foot
    - Create binned/categorical versions of continuous features
    - Create interaction features if meaningful
    - Document reasoning for each new feature
11. Advanced visualizations
    - Create publication-quality plots
    - Customize colors, labels, titles
    - Use consistent style across all plots
    - Save all plots: `plt.savefig('output/figures/plot_name.png', dpi=300)`

**Step 6: Final Analysis & Insights** (Day 13)
12. Create `04_analysis.ipynb`
    - Answer all original questions from Step 1
    - Provide evidence with visualizations and statistics
    - Create summary tables
    - Generate key insights and recommendations
13. Business recommendations
    - Based on findings, what actions should be taken?
    - Quantify impact where possible
    - Be specific and actionable

**Step 7: Documentation & Polish** (Days 14-15)
14. Create professional README.md
    - Project title and description
    - Business problem or research questions
    - Data source and description
    - Methodology
    - Key findings (with 2-3 key visualizations embedded)
    - Technologies used
    - How to reproduce (installation and usage instructions)
    - Future work and limitations
15. Export and organize deliverables
    - Export notebook to HTML: File > Download as > HTML
    - Create Python script version (if needed)
    - Organize all figures in output/figures/
    - Create requirements.txt: `pip freeze > requirements.txt`
    - Clean up notebooks (remove experimental cells)
16. Final commits and push
    - Review all files before committing
    - Commit with descriptive message
    - Push to GitHub
    - Verify everything displays correctly on GitHub

**Step 8: Share Your Work** (Day 16)
17. Share on LinkedIn
    - Write a post about your capstone project
    - Include 2-3 key visualizations
    - Share link to GitHub repository
    - Mention 1-2 interesting insights you found
    - Use hashtags: #DataScience #DataAnalysis #Python
18. Add to portfolio website
    - Feature this as a main project
    - Include description and link
    - Show preview visualizations

**Evaluation Criteria:**
- Code quality and organization (25%)
- Depth of analysis (25%)
- Quality of visualizations (20%)
- Documentation and presentation (20%)
- Insights and conclusions (10%)

**Submission:**
- Push to GitHub with professional README
- Share link on LinkedIn with key findings
- Add to your portfolio website

**Achievement Unlocked:** üèÜ Data Analyst - Complete comprehensive capstone project

**Progress:** `[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100%`

[‚Üë Back to Top](#-table-of-contents)

---

## ‚úÖ Assessment Checklist

### Technical Skills Self-Assessment

Before moving to Intermediate level, honestly evaluate your abilities:

**Python Programming:**
- [ ] I can write Python scripts with functions and classes
- [ ] I understand OOP principles and can apply them
- [ ] I can debug Python code effectively
- [ ] I'm comfortable with Jupyter notebooks
- [ ] I can handle files and data I/O confidently

**Mathematics:**
- [ ] I understand vectors and matrices conceptually
- [ ] I grasp basic calculus concepts (derivatives, gradients)
- [ ] I can compute and interpret statistical measures
- [ ] I understand probability and distributions basics
- [ ] I can implement math operations in NumPy

**Data Manipulation:**
- [ ] I can load and clean data with Pandas
- [ ] I'm proficient with filtering, grouping, merging
- [ ] I can handle missing data appropriately
- [ ] I understand time series operations
- [ ] I can transform and engineer features

**Data Visualization:**
- [ ] I can create meaningful visualizations with matplotlib
- [ ] I use seaborn for statistical plots effectively
- [ ] I can conduct thorough exploratory data analysis
- [ ] I choose appropriate plot types for different data
- [ ] My visualizations are clear and professional

**Tools & Workflow:**
- [ ] I use Git and GitHub for all projects
- [ ] I write clear documentation and READMEs
- [ ] I manage virtual environments
- [ ] I follow Python coding best practices
- [ ] I have a professional portfolio on GitHub

**Projects:**
- [ ] I've completed at least 15 hands-on projects
- [ ] All projects are on GitHub with documentation
- [ ] I can explain my project decisions and code
- [ ] I've completed the capstone project

### Readiness Criteria

**You're ready for Intermediate level if:**
- You scored 90%+ on the self-assessment above
- You can complete a new EDA project independently in 4-6 hours
- You're comfortable reading and writing 100+ lines of Python
- You can debug errors without constant Stack Overflow searches
- You've built a portfolio with 15+ projects
- You understand when to use different data structures and libraries

**If not quite ready:**
- Spend extra time on weak areas
- Repeat projects from scratch without looking at solutions
- Take on 2-3 more Kaggle datasets for practice
- Consider peer code review or mentorship

[‚Üë Back to Top](#-table-of-contents)

---

## Next Steps

### Transition to Intermediate Level

**File to Open Next:** `02_Intermediate_Roadmap.md`

**What's Coming in Intermediate:**
- Machine Learning algorithms and theory
- Scikit-learn for ML model building
- Model evaluation and validation techniques
- Deep Learning fundamentals
- Neural Networks and CNNs
- Computer Vision with OpenCV
- Natural Language Processing basics
- Real-world ML project deployment

**Preparation Before Starting Intermediate:**
1. Ensure all assessment criteria are met
2. Review any weak areas in beginner content
3. Take a 3-4 day break to consolidate learning
4. Set up ML-specific libraries (scikit-learn, TensorFlow)
5. Review linear algebra and calculus concepts

### Additional Learning Resources

<details>
<summary><strong>Books to Read (Optional)</strong></summary>

- "Python Data Science Handbook" by Jake VanderPlas (FREE online)
- "Python for Data Analysis" by Wes McKinney (Pandas creator)
- "Automate the Boring Stuff with Python" by Al Sweigart (FREE online)

</details>

**Communities to Join:**
- [r/learnpython](https://www.reddit.com/r/learnpython/)
- [r/datascience](https://www.reddit.com/r/datascience/)
- [Kaggle Community](https://www.kaggle.com/discussions)
- [Python Discord](https://discord.gg/python)

**Keep Practicing:**
- Complete 1-2 Kaggle datasets per week
- Participate in Kaggle competitions (start with "Getting Started" comps)
- Write technical blog posts about your learning
- Help beginners on forums (teaching reinforces learning)

[‚Üë Back to Top](#-table-of-contents)

---

## Gamification Summary

**Total XP Available:** 10,000 XP

**Your Progress:**
- Module 1: 2,000 XP ‚ö°
- Module 2: 1,500 XP ‚ö°
- Module 3: 2,500 XP ‚ö°
- Module 4: 2,000 XP ‚ö°
- Module 5: 1,000 XP ‚ö°
- Capstone: 1,000 XP ‚ö°

**Achievements Available:**
- üèÜ Python Initiate - Complete Week 1-2 exercises
- üèÜ OOP Master - Build complex multi-class systems
- üèÜ Math Ninja - Complete all math exercises
- üèÜ Data Wrangler - Master Pandas operations
- üèÜ Visualization Expert - Create 50+ plots
- üèÜ Git Guardian - Build professional portfolio
- üèÜ Data Analyst - Complete capstone project
- üèÜ Consistent Learner - 30-day learning streak
- üèÜ Helper - Answer 10 questions in forums
- üèÜ Blogger - Write first technical blog post

**Level Progression:**
- 0-2,000 XP: Python Initiate
- 2,001-4,000 XP: Data Apprentice
- 4,001-6,000 XP: Data Wrangler
- 6,001-8,000 XP: Visualization Expert
- 8,001-10,000 XP: AI Foundation Builder

**Track Your Progress:**
Create a simple spreadsheet or use a notebook to track:
- Daily hours studied
- Modules completed
- XP earned
- Projects finished
- Concepts mastered

[‚Üë Back to Top](#-table-of-contents)

---

## Motivational Reminders

> "The expert in anything was once a beginner." - Helen Hayes

**Success Tips:**
1. **Consistency beats intensity** - 2 hours daily beats 14 hours on Sunday
2. **Build projects** - You'll learn more from one project than 10 tutorials
3. **Document everything** - Your future self will thank you
4. **Ask for help** - No one learns in isolation
5. **Celebrate small wins** - Finished a section? Celebrate!
6. **Compare to your past self** - Not to others
7. **Enjoy the journey** - You're building an amazing skill set

**When You Feel Stuck:**
- Take a 15-minute break and come back fresh
- Explain the problem out loud (rubber duck debugging)
- Search: "[your error] python [version]" on Google
- Ask on Stack Overflow or Discord
- Revisit fundamentals if needed
- Remember: Every expert was once confused by this too

**You Can Do This!** üí™

---

**Version:** 1.2
**Last Updated:** January 2026
**Status:** Ready to Begin! üöÄ

---

**Next File:** [02_Intermediate_Roadmap.md](./02_Intermediate_Roadmap.md)

[‚Üë Back to Top](#-table-of-contents)
